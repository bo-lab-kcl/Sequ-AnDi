{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b35de9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import csv\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import math\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from matplotlib import cm\n",
    "import scipy.interpolate as interp\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd1db4a",
   "metadata": {},
   "source": [
    "THIS IS THE ENSEMBLE PROCESSING ON THE DATA FROM THE SUBMISSION FROM SATURDAY 13.\n",
    "POSTPROCESSING\n",
    "\n",
    "exp0 and 1 and 10 are probably just one cluster\n",
    "\n",
    "\n",
    "\n",
    "exp2 Ensemble replace trap cluster with 0,0\n",
    "exp2 Traj replace trap cluster with the additional condition that alpha<0.25 with 0,0\n",
    "\n",
    "exp3 probably confined Ensemble replace trap cluster with 0,0 not sure\n",
    "exp3 Traj replace trap cluster with the additional condition that k<0.25 (or similar) with 0,0 not sure\n",
    "\n",
    "\n",
    "\n",
    "exp 5 looks like 1 cluster but has a lot of CP\n",
    "\n",
    "6 is just one?\n",
    "\n",
    "exp4, 7 and  11 have likely three states\n",
    "\n",
    "PARTS OF THIS IS BASED ON COUNTING THE CP, WHICH IS DONE IN THE CELL BELOW HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eaa4b53-f895-4caa-a342-d6203213224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EXP = 12 # number of experiments\n",
    "N_FOVS = 30 # number of fields of view per experiment\n",
    "\n",
    "# Single-trajectory predictions dataset filepath, where results from ChallengePredictions.ipynb are stored.\n",
    "path_track = \"track_2/\"\n",
    "\n",
    "# note this notebook saves pdf's and npy's in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e0afcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp 0\n",
      "n traj 999 n segments 1006\n",
      "exp 1\n",
      "n traj 1007 n segments 1014\n",
      "exp 2\n",
      "n traj 1394 n segments 2312\n",
      "exp 3\n",
      "n traj 1170 n segments 2100\n",
      "exp 4\n",
      "n traj 6437 n segments 14905\n",
      "exp 5\n",
      "n traj 1333 n segments 3157\n",
      "exp 6\n",
      "n traj 1299 n segments 2294\n",
      "exp 7\n",
      "n traj 8767 n segments 27397\n",
      "exp 8\n",
      "n traj 1232 n segments 1413\n",
      "exp 9\n",
      "n traj 1263 n segments 2417\n",
      "exp 10\n",
      "n traj 1556 n segments 1630\n",
      "exp 11\n",
      "n traj 1812 n segments 9543\n"
     ]
    }
   ],
   "source": [
    "# COUNTING CHANGEPOINTS (LONG WAY BUT IT WORKS)\n",
    "import os\n",
    "for exp in range(N_EXP):\n",
    "# for exp in range(0,1):\n",
    "\n",
    "    print(\"exp \"+str(exp))\n",
    "    # Define the directory where the files are stored\n",
    "    directory = path_track+'exp_'+str(exp)\n",
    "\n",
    "    # Initialize an empty list to store the arrays\n",
    "    arrays = []\n",
    "\n",
    "    aa = []\n",
    "\n",
    "    for fovIdx in range(N_FOVS):\n",
    "#         print(\"fov \"+str(fovIdx))\n",
    "\n",
    "    #     print(fovIdx)\n",
    "        filename = f'fov_{fovIdx}.txt'\n",
    "    #     print(filename)\n",
    "        filepath = os.path.join(directory, filename)\n",
    "    #     print(filepath)\n",
    "        with open(filepath) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row in csv_reader:\n",
    "    #           \n",
    "                aa.append([float(row[i]) for i in range(len(row)) if ((i)%4==2 and i!=0)]) \n",
    "#     print(len(aa))\n",
    "\n",
    "    af = np.array(list(itertools.chain.from_iterable(aa)))\n",
    "\n",
    "    print(\"n traj\",len(aa),\"n segments\",len(af))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for experiment 0,1, and 10 we believe there is a single state so we don't cluster\n",
    "\n",
    "import os\n",
    "# import numpy as np\n",
    "for exp in [0,1,10]:\n",
    "# for exp in range(0,12):\n",
    "# for exp in range(0,1):\n",
    "\n",
    "    # Specify the number of clusters\n",
    "    k_set = 1\n",
    "\n",
    "\n",
    "    print(\"exp \"+str(exp))\n",
    "    # Define the directory where the files are stored\n",
    "    directory = path_track+'exp_'+str(exp)\n",
    "\n",
    "    # Initialize an empty list to store the arrays\n",
    "    arrays = []\n",
    "    # Ys = []\n",
    "    kk = []\n",
    "    aa = []\n",
    "    tt = []\n",
    "    for fovIdx in range(N_FOVS):\n",
    "        print(\"fov \"+str(fovIdx))\n",
    "\n",
    "    #     print(fovIdx)\n",
    "        filename = f'fov_{fovIdx}.txt'\n",
    "    #     print(filename)\n",
    "        filepath = os.path.join(directory, filename)\n",
    "    #     print(filepath)\n",
    "        with open(filepath) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row in csv_reader:\n",
    "    #             Ys.append(np.array([float(i) for i in row[1:]])) # K, a, 2.0, length (K and a in reverse order as ensemble label..)\n",
    "                kk.append([float(row[i]) for i in range(len(row)) if ((i)%4==1 and i!=0)]) \n",
    "        \n",
    "                aa.append([float(row[i]) for i in range(len(row)) if ((i)%4==2 and i!=0)]) \n",
    "                tt.append([float(row[i]) for i in range(len(row)) if ((i)%4==0 and i!=0)]) \n",
    "\n",
    "    af = np.array(list(itertools.chain.from_iterable(aa)))\n",
    "    kf = np.array(list(itertools.chain.from_iterable(kk)))\n",
    "#     tf = np.array(list(itertools.chain.from_iterable(tt)))\n",
    "\n",
    "    if  np.isnan(af).any()== True :\n",
    "\n",
    "        print(\"nan alpha at exp \",exp, \"in pos\",np.where(np.isnan(af)))\n",
    "#     if  np.isnan(kf).any()== True :\n",
    "\n",
    "#         print(\"nan k at exp \",exp, \"at fov\",fovIdx)\n",
    "    # Extracting the length of each segment\n",
    "    af = np.nan_to_num(af, copy=True, nan=0.001, posinf=None, neginf=None)\n",
    "    kf = np.nan_to_num(kf, copy=True, nan=0.001, posinf=None, neginf=None)\n",
    "\n",
    "    \n",
    "    tdif = []\n",
    "    for i in range(len(tt)):\n",
    "        td = np.diff(tt[i]) # difference between successive change points\n",
    "        tf = tt[i][0]       #The first entry in tt[i] is the length of the first segment\n",
    "        ts = np.array(np.append(tf,td)) # creating the vector of segment lenght for trajectory i\n",
    "        tdif.append(ts)\n",
    "    tdf = np.array(list(itertools.chain.from_iterable(tdif)))    #flattening the list into a 1d array\n",
    "    if  np.isnan(tdf).any()== True :\n",
    "\n",
    "        print(\"nan t at exp \",exp, \"at fov\",fovIdx)\n",
    "\n",
    "\n",
    "    tdf = np.nan_to_num(tdf, copy=True, nan=0.001, posinf=None, neginf=None)\n",
    "\n",
    "    # Example arrays of coordinates\n",
    "    x = af\n",
    "    y = kf\n",
    "    \n",
    "#     If you want to use time uncomment z\n",
    "#     z = tdf\n",
    "#     coordinates = np.column_stack((x, y, z))\n",
    "\n",
    "    # Combine the x and y coordinates into a single array\n",
    "    coordinates = np.column_stack((x, y))\n",
    "#     coordinates = np.nan_to_num(coordinates, copy=True, nan=0.001, posinf=None, neginf=None)\n",
    "\n",
    "\n",
    "    # Create the KMeans model\n",
    "    kmeans = KMeans(n_clusters=k_set, random_state=0, n_init =30)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    kmeans.fit(coordinates)\n",
    "\n",
    "    # Predict the cluster for each data point\n",
    "    # labels = kmeans.predict(coordinates)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Get the cluster centers\n",
    "    centers = kmeans.cluster_centers_\n",
    "\n",
    "    # Print the cluster labels and centers\n",
    "    print(\"Cluster Labels:\", labels)\n",
    "    print(\"Cluster Centers:\\n\", centers)\n",
    "    fig = plt.figure()# Plot the results\n",
    "    plt.scatter(coordinates[:, 0], coordinates[:, 1], c=labels, cmap='viridis', marker='o', s =0.2)\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='x')\n",
    "    plt.xlabel('$\\\\alpha$')\n",
    "    plt.ylabel('K')\n",
    "    plt.xlim(0,2)\n",
    "\n",
    "    plt.title('K-Means Clustering for exp'+str(exp))\n",
    "    plt.show()\n",
    "    fig.savefig('exp_'+str(exp)+'.pdf')\n",
    "    \n",
    "    \n",
    "    fig = plt.figure()# Plot the results\n",
    "    plt.scatter(coordinates[:, 0], coordinates[:, 1], c=labels, cmap='viridis', marker='o', s =0.2)\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='x')\n",
    "    plt.xlabel('$\\\\alpha$')\n",
    "    plt.ylabel('K')\n",
    "    plt.xlim(0,2)\n",
    "    plt.ylim(0.001,16)\n",
    "    plt.title('K-Means Clustering for exp'+str(exp))\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "    fig.savefig('exp_'+str(exp)+'_log.pdf')\n",
    "    \n",
    "#     mma = [np.mean(af[labels==0]),np.mean(af[labels==1])]\n",
    "#     stda = [np.std(af[labels==0]),np.std(af[labels==1])]\n",
    "\n",
    "#     mmk = [np.mean(kf[labels==0]),np.mean(kf[labels==1])]\n",
    "#     stdk = [np.std(kf[labels==0]),np.std(kf[labels==1])]\n",
    "\n",
    "#     np.save(\"mean_a\"+str(exp),mma)\n",
    "#     np.save(\"std_a\"+str(exp),stda)\n",
    "\n",
    "#     np.save(\"mean_k\"+str(exp),mmk)\n",
    "#     np.save(\"std_k\"+str(exp),stdk)\n",
    "\n",
    "    \n",
    "    # The time spent in a cluster is the sum of the length of the duration of all the segments belonging to a cluster\n",
    "#     tdf_lab = []\n",
    "    tdf_tot = []\n",
    "#     tdf_mean = []\n",
    "    mma = []\n",
    "    stda = []\n",
    "    mmk = []\n",
    "    stdk = []\n",
    "    for i in range(k_set):\n",
    "    #     print(i)\n",
    "        tdf_l = tdf[labels == i] #duration for segments in class i\n",
    "        a_l = af[labels == i] #alpha for segments in class i\n",
    "        k_l = kf[labels == i] #k for segments in class i\n",
    "\n",
    "        mma.append(np.mean(a_l)) #mean alpha for segments in class i\n",
    "        stda.append(np.std(a_l)) #std of alpha for segments in class i\n",
    "        \n",
    "        mmk.append(np.mean(k_l)) #mean k for segments in class i\n",
    "        stdk.append(np.std(k_l)) #std of k for segments in class i\n",
    "        \n",
    "#         tdf_lab.append(tdf_l)\n",
    "        tdf_tot.append(np.sum(tdf_l)) # total time spent in class i\n",
    "#         tdf_mean.append(np.mean(tdf_l)) \n",
    "\n",
    "        \n",
    "    np.save(\"mean_a\"+str(exp),mma)\n",
    "    np.save(\"std_a\"+str(exp),stda)\n",
    "\n",
    "    np.save(\"mean_k\"+str(exp),mmk)\n",
    "    np.save(\"std_k\"+str(exp),stdk)    \n",
    "    np.save(\"std_k\"+str(exp),stdk)    \n",
    "\n",
    "#     Normalising the amount of time spent in each state\n",
    "    tdf_norm = np.array(tdf_tot)\n",
    "#     print(tdf_norm)\n",
    "    tot_t = np.sum(tdf_norm)\n",
    "#     print(tot_t)\n",
    "    tdf_norm = tdf_norm/tot_t\n",
    "#     print(tdf_norm)\n",
    "    np.save(\"time\"+str(exp),tdf_norm)    \n",
    "    \n",
    "        \n",
    "    \n",
    "    print(\"mean $\\\\alpha$\",mma,\"\\n\",\"mean K\",mmk,\"\\n\",\"std $\\\\alpha$\",stda,\"\\n\",\"std k\",stdk,\"\\n\",\"time\",tdf_norm)\n",
    "    \n",
    "    inertia = []\n",
    "    k_range = range(1, 6)\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0, n_init =30)\n",
    "        kmeans.fit(coordinates)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "\n",
    "    # Plot the Elbow Method\n",
    "    fig2 = plt.figure(figsize=(8, 5))\n",
    "    plt.plot(k_range, inertia, 'bo-')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('Inertia (Sum of squared distances)')\n",
    "    plt.title('Elbow Method For Optimal k for exp'+str(exp))\n",
    "    plt.show()\n",
    "    fig2.savefig('elbow_exp_'+str(exp)+'.pdf')\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcbc991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for experiment 4,7, and 11 we believe there are three states so we do look for 3 clusters\n",
    "\n",
    "import os\n",
    "# import numpy as np\n",
    "for exp in [4,7,11]:\n",
    "# for exp in range(0,12):\n",
    "# for exp in range(0,1):\n",
    "\n",
    "    # Specify the number of clusters\n",
    "    k_set = 3\n",
    "\n",
    "\n",
    "    print(\"exp \"+str(exp))\n",
    "    # Define the directory where the files are stored\n",
    "    directory = path_track+'exp_'+str(exp)\n",
    "\n",
    "    # Initialize an empty list to store the arrays\n",
    "    arrays = []\n",
    "    # Ys = []\n",
    "    kk = []\n",
    "    aa = []\n",
    "    tt = []\n",
    "    for fovIdx in range(N_FOVS):\n",
    "        print(\"fov \"+str(fovIdx))\n",
    "\n",
    "    #     print(fovIdx)\n",
    "        filename = f'fov_{fovIdx}.txt'\n",
    "    #     print(filename)\n",
    "        filepath = os.path.join(directory, filename)\n",
    "    #     print(filepath)\n",
    "        with open(filepath) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row in csv_reader:\n",
    "    #             Ys.append(np.array([float(i) for i in row[1:]])) # K, a, 2.0, length (K and a in reverse order as ensemble label..)\n",
    "                kk.append([float(row[i]) for i in range(len(row)) if ((i)%4==1 and i!=0)]) \n",
    "        \n",
    "                aa.append([float(row[i]) for i in range(len(row)) if ((i)%4==2 and i!=0)]) \n",
    "                tt.append([float(row[i]) for i in range(len(row)) if ((i)%4==0 and i!=0)]) \n",
    "\n",
    "    af = np.array(list(itertools.chain.from_iterable(aa)))\n",
    "    kf = np.array(list(itertools.chain.from_iterable(kk)))\n",
    "#     tf = np.array(list(itertools.chain.from_iterable(tt)))\n",
    "\n",
    "    if  np.isnan(af).any()== True :\n",
    "\n",
    "        print(\"nan alpha at exp \",exp, \"in pos\",np.where(np.isnan(af)))\n",
    "#     if  np.isnan(kf).any()== True :\n",
    "\n",
    "#         print(\"nan k at exp \",exp, \"at fov\",fovIdx)\n",
    "    # Extracting the length of each segment\n",
    "    af = np.nan_to_num(af, copy=True, nan=0.001, posinf=None, neginf=None)\n",
    "    kf = np.nan_to_num(kf, copy=True, nan=0.001, posinf=None, neginf=None)\n",
    "\n",
    "    \n",
    "    tdif = []\n",
    "    for i in range(len(tt)):\n",
    "        td = np.diff(tt[i]) # difference between successive change points\n",
    "        tf = tt[i][0]       #The first entry in tt[i] is the length of the first segment\n",
    "        ts = np.array(np.append(tf,td)) # creating the vector of segment lenght for trajectory i\n",
    "        tdif.append(ts)\n",
    "    tdf = np.array(list(itertools.chain.from_iterable(tdif)))    #flattening the list into a 1d array\n",
    "    if  np.isnan(tdf).any()== True :\n",
    "\n",
    "        print(\"nan t at exp \",exp, \"at fov\",fovIdx)\n",
    "\n",
    "\n",
    "    tdf = np.nan_to_num(tdf, copy=True, nan=0.001, posinf=None, neginf=None)\n",
    "\n",
    "    # Example arrays of coordinates\n",
    "    x = af\n",
    "    y = kf\n",
    "    \n",
    "#     If you want to use time uncomment z\n",
    "#     z = tdf\n",
    "#     coordinates = np.column_stack((x, y, z))\n",
    "\n",
    "    # Combine the x and y coordinates into a single array\n",
    "    coordinates = np.column_stack((x, y))\n",
    "#     coordinates = np.nan_to_num(coordinates, copy=True, nan=0.001, posinf=None, neginf=None)\n",
    "\n",
    "\n",
    "    # Create the KMeans model\n",
    "    kmeans = KMeans(n_clusters=k_set, random_state=0, n_init =30)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    kmeans.fit(coordinates)\n",
    "\n",
    "    # Predict the cluster for each data point\n",
    "    # labels = kmeans.predict(coordinates)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Get the cluster centers\n",
    "    centers = kmeans.cluster_centers_\n",
    "\n",
    "    # Print the cluster labels and centers\n",
    "    print(\"Cluster Labels:\", labels)\n",
    "    print(\"Cluster Centers:\\n\", centers)\n",
    "    fig = plt.figure()# Plot the results\n",
    "    plt.scatter(coordinates[:, 0], coordinates[:, 1], c=labels, cmap='viridis', marker='o', s =0.2)\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='x')\n",
    "    plt.xlabel('$\\\\alpha$')\n",
    "    plt.ylabel('K')\n",
    "    plt.xlim(0,2)\n",
    "\n",
    "    plt.title('K-Means Clustering for exp'+str(exp))\n",
    "    plt.show()\n",
    "    fig.savefig('exp_'+str(exp)+'.pdf')\n",
    "    \n",
    "    \n",
    "    fig = plt.figure()# Plot the results\n",
    "    plt.scatter(coordinates[:, 0], coordinates[:, 1], c=labels, cmap='viridis', marker='o', s =0.2)\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='x')\n",
    "    plt.xlabel('$\\\\alpha$')\n",
    "    plt.ylabel('K')\n",
    "    plt.xlim(0,2)\n",
    "    plt.ylim(0.001,16)\n",
    "    plt.title('K-Means Clustering for exp'+str(exp))\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "    fig.savefig('exp_'+str(exp)+'_log.pdf')\n",
    "    \n",
    " \n",
    "    # The time spent in a cluster is the sum of the length of the duration of all the segments belonging to a cluster\n",
    "#     tdf_lab = []\n",
    "    tdf_tot = []\n",
    "#     tdf_mean = []\n",
    "    mma = []\n",
    "    stda = []\n",
    "    mmk = []\n",
    "    stdk = []\n",
    "    for i in range(k_set):\n",
    "    #     print(i)\n",
    "        tdf_l = tdf[labels == i] #duration for segments in class i\n",
    "        a_l = af[labels == i] #alpha for segments in class i\n",
    "        k_l = kf[labels == i] #k for segments in class i\n",
    "\n",
    "        mma.append(np.mean(a_l)) #mean alpha for segments in class i\n",
    "        stda.append(np.std(a_l)) #std of alpha for segments in class i\n",
    "        \n",
    "        mmk.append(np.mean(k_l)) #mean k for segments in class i\n",
    "        stdk.append(np.std(k_l)) #std of k for segments in class i\n",
    "        \n",
    "#         tdf_lab.append(tdf_l)\n",
    "        tdf_tot.append(np.sum(tdf_l)) # total time spent in class i\n",
    "#         tdf_mean.append(np.mean(tdf_l)) \n",
    "\n",
    "        \n",
    "    np.save(\"mean_a\"+str(exp),mma)\n",
    "    np.save(\"std_a\"+str(exp),stda)\n",
    "\n",
    "    np.save(\"mean_k\"+str(exp),mmk)\n",
    "    np.save(\"std_k\"+str(exp),stdk)    \n",
    "    np.save(\"std_k\"+str(exp),stdk)    \n",
    "\n",
    "#     Normalising the amount of time spent in each state\n",
    "    tdf_norm = np.array(tdf_tot)\n",
    "#     print(tdf_norm)\n",
    "    tot_t = np.sum(tdf_norm)\n",
    "#     print(tot_t)\n",
    "    tdf_norm = tdf_norm/tot_t\n",
    "#     print(tdf_norm)\n",
    "    np.save(\"time\"+str(exp),tdf_norm)    \n",
    "    \n",
    "        \n",
    "    \n",
    "    print(\"mean $\\\\alpha$\",mma,\"\\n\",\"mean K\",mmk,\"\\n\",\"std $\\\\alpha$\",stda,\"\\n\",\"std k\",stdk,\"\\n\",\"time\",tdf_norm)\n",
    "    \n",
    "    inertia = []\n",
    "    k_range = range(1, 6)\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0, n_init =30)\n",
    "        kmeans.fit(coordinates)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "\n",
    "    # Plot the Elbow Method\n",
    "    fig2 = plt.figure(figsize=(8, 5))\n",
    "    plt.plot(k_range, inertia, 'bo-')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('Inertia (Sum of squared distances)')\n",
    "    plt.title('Elbow Method For Optimal k for exp'+str(exp))\n",
    "    plt.show()\n",
    "    fig2.savefig('elbow_exp_'+str(exp)+'.pdf')\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50fa04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for experiment the other ones 2,3,5,6,8,9 we believe there are two states so we do look for 2 clusters\n",
    "\n",
    "import os\n",
    "# import numpy as np\n",
    "for exp in [2,3,5,6,8,9]:\n",
    "# for exp in range(0,12):\n",
    "# for exp in range(0,1):\n",
    "\n",
    "    # Specify the number of clusters\n",
    "    k_set = 2\n",
    "\n",
    "\n",
    "    print(\"exp \"+str(exp))\n",
    "    # Define the directory where the files are stored\n",
    "    directory = path_track+'exp_'+str(exp)\n",
    "\n",
    "    # Initialize an empty list to store the arrays\n",
    "    arrays = []\n",
    "    # Ys = []\n",
    "    kk = []\n",
    "    aa = []\n",
    "    tt = []\n",
    "    for fovIdx in range(N_FOVS):\n",
    "        print(\"fov \"+str(fovIdx))\n",
    "\n",
    "    #     print(fovIdx)\n",
    "        filename = f'fov_{fovIdx}.txt'\n",
    "    #     print(filename)\n",
    "        filepath = os.path.join(directory, filename)\n",
    "    #     print(filepath)\n",
    "        with open(filepath) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row in csv_reader:\n",
    "    #             Ys.append(np.array([float(i) for i in row[1:]])) # K, a, 2.0, length (K and a in reverse order as ensemble label..)\n",
    "                kk.append([float(row[i]) for i in range(len(row)) if ((i)%4==1 and i!=0)]) \n",
    "        \n",
    "                aa.append([float(row[i]) for i in range(len(row)) if ((i)%4==2 and i!=0)]) \n",
    "                tt.append([float(row[i]) for i in range(len(row)) if ((i)%4==0 and i!=0)]) \n",
    "\n",
    "    af = np.array(list(itertools.chain.from_iterable(aa)))\n",
    "    kf = np.array(list(itertools.chain.from_iterable(kk)))\n",
    "#     tf = np.array(list(itertools.chain.from_iterable(tt)))\n",
    "\n",
    "    if  np.isnan(af).any()== True :\n",
    "\n",
    "        print(\"nan alpha at exp \",exp, \"in pos\",np.where(np.isnan(af)))\n",
    "#     if  np.isnan(kf).any()== True :\n",
    "\n",
    "#         print(\"nan k at exp \",exp, \"at fov\",fovIdx)\n",
    "    # Extracting the length of each segment\n",
    "    af = np.nan_to_num(af, copy=True, nan=0.001, posinf=None, neginf=None)\n",
    "    kf = np.nan_to_num(kf, copy=True, nan=0.001, posinf=None, neginf=None)\n",
    "\n",
    "    \n",
    "    tdif = []\n",
    "    for i in range(len(tt)):\n",
    "        td = np.diff(tt[i]) # difference between successive change points\n",
    "        tf = tt[i][0]       #The first entry in tt[i] is the length of the first segment\n",
    "        ts = np.array(np.append(tf,td)) # creating the vector of segment lenght for trajectory i\n",
    "        tdif.append(ts)\n",
    "    tdf = np.array(list(itertools.chain.from_iterable(tdif)))    #flattening the list into a 1d array\n",
    "    if  np.isnan(tdf).any()== True :\n",
    "\n",
    "        print(\"nan t at exp \",exp, \"at fov\",fovIdx)\n",
    "\n",
    "\n",
    "    tdf = np.nan_to_num(tdf, copy=True, nan=0.001, posinf=None, neginf=None)\n",
    "\n",
    "    # Example arrays of coordinates\n",
    "    x = af\n",
    "    y = kf\n",
    "    \n",
    "#     If you want to use time uncomment z\n",
    "#     z = tdf\n",
    "#     coordinates = np.column_stack((x, y, z))\n",
    "\n",
    "    # Combine the x and y coordinates into a single array\n",
    "    coordinates = np.column_stack((x, y))\n",
    "#     coordinates = np.nan_to_num(coordinates, copy=True, nan=0.001, posinf=None, neginf=None)\n",
    "\n",
    "\n",
    "    # Create the KMeans model\n",
    "    kmeans = KMeans(n_clusters=k_set, random_state=0, n_init =30)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    kmeans.fit(coordinates)\n",
    "\n",
    "    # Predict the cluster for each data point\n",
    "    # labels = kmeans.predict(coordinates)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Get the cluster centers\n",
    "    centers = kmeans.cluster_centers_\n",
    "\n",
    "    # Print the cluster labels and centers\n",
    "    print(\"Cluster Labels:\", labels)\n",
    "    print(\"Cluster Centers:\\n\", centers)\n",
    "    fig = plt.figure()# Plot the results\n",
    "    plt.scatter(coordinates[:, 0], coordinates[:, 1], c=labels, cmap='viridis', marker='o', s =0.2)\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='x')\n",
    "    plt.xlabel('$\\\\alpha$')\n",
    "    plt.ylabel('K')\n",
    "    plt.xlim(0,2)\n",
    "\n",
    "    plt.title('K-Means Clustering for exp'+str(exp))\n",
    "    plt.show()\n",
    "    fig.savefig('exp_'+str(exp)+'.pdf')\n",
    "    \n",
    "    \n",
    "    fig = plt.figure()# Plot the results\n",
    "    plt.scatter(coordinates[:, 0], coordinates[:, 1], c=labels, cmap='viridis', marker='o', s =0.2)\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='x')\n",
    "    plt.xlabel('$\\\\alpha$')\n",
    "    plt.ylabel('K')\n",
    "    plt.xlim(0,2)\n",
    "    plt.ylim(0.001,16)\n",
    "    plt.title('K-Means Clustering for exp'+str(exp))\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "    fig.savefig('exp_'+str(exp)+'_log.pdf')\n",
    "    \n",
    "#     mma = [np.mean(af[labels==0]),np.mean(af[labels==1])]\n",
    "#     stda = [np.std(af[labels==0]),np.std(af[labels==1])]\n",
    "\n",
    "#     mmk = [np.mean(kf[labels==0]),np.mean(kf[labels==1])]\n",
    "#     stdk = [np.std(kf[labels==0]),np.std(kf[labels==1])]\n",
    "\n",
    "#     np.save(\"mean_a\"+str(exp),mma)\n",
    "#     np.save(\"std_a\"+str(exp),stda)\n",
    "\n",
    "#     np.save(\"mean_k\"+str(exp),mmk)\n",
    "#     np.save(\"std_k\"+str(exp),stdk)\n",
    "\n",
    "    \n",
    "    # The time spent in a cluster is the sum of the length of the duration of all the segments belonging to a cluster\n",
    "#     tdf_lab = []\n",
    "    tdf_tot = []\n",
    "#     tdf_mean = []\n",
    "    mma = []\n",
    "    stda = []\n",
    "    mmk = []\n",
    "    stdk = []\n",
    "    for i in range(k_set):\n",
    "    #     print(i)\n",
    "        tdf_l = tdf[labels == i] #duration for segments in class i\n",
    "        a_l = af[labels == i] #alpha for segments in class i\n",
    "        k_l = kf[labels == i] #k for segments in class i\n",
    "\n",
    "        mma.append(np.mean(a_l)) #mean alpha for segments in class i\n",
    "        stda.append(np.std(a_l)) #std of alpha for segments in class i\n",
    "        \n",
    "        mmk.append(np.mean(k_l)) #mean k for segments in class i\n",
    "        stdk.append(np.std(k_l)) #std of k for segments in class i\n",
    "        \n",
    "#         tdf_lab.append(tdf_l)\n",
    "        tdf_tot.append(np.sum(tdf_l)) # total time spent in class i\n",
    "#         tdf_mean.append(np.mean(tdf_l)) \n",
    "\n",
    "        \n",
    "    np.save(\"mean_a\"+str(exp),mma)\n",
    "    np.save(\"std_a\"+str(exp),stda)\n",
    "\n",
    "    np.save(\"mean_k\"+str(exp),mmk)\n",
    "    np.save(\"std_k\"+str(exp),stdk)    \n",
    "    np.save(\"std_k\"+str(exp),stdk)    \n",
    "\n",
    "#     Normalising the amount of time spent in each state\n",
    "    tdf_norm = np.array(tdf_tot)\n",
    "#     print(tdf_norm)\n",
    "    tot_t = np.sum(tdf_norm)\n",
    "#     print(tot_t)\n",
    "    tdf_norm = tdf_norm/tot_t\n",
    "#     print(tdf_norm)\n",
    "    np.save(\"time\"+str(exp),tdf_norm)    \n",
    "    \n",
    "        \n",
    "    \n",
    "    print(\"mean $\\\\alpha$\",mma,\"\\n\",\"mean K\",mmk,\"\\n\",\"std $\\\\alpha$\",stda,\"\\n\",\"std k\",stdk,\"\\n\",\"time\",tdf_norm)\n",
    "    \n",
    "    inertia = []\n",
    "    k_range = range(1, 6)\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0, n_init =30)\n",
    "        kmeans.fit(coordinates)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "\n",
    "    # Plot the Elbow Method\n",
    "    fig2 = plt.figure(figsize=(8, 5))\n",
    "    plt.plot(k_range, inertia, 'bo-')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('Inertia (Sum of squared distances)')\n",
    "    plt.title('Elbow Method For Optimal k for exp'+str(exp))\n",
    "    plt.show()\n",
    "    fig2.savefig('elbow_exp_'+str(exp)+'.pdf')\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8301be49",
   "metadata": {},
   "source": [
    "SINCE EXP 2 IS CLEARLY TRAPPED WE ASSIGN A VERY SMALL MEAN AND AVERAGE TO BOTH K AND ALPHA, OVERWRITING THE WHAT THE CLUSTER SAID. THIS IS POTENTIALLY DANGEROUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebbb101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean alpha [1.0067722  0.04544294] mean K [1.07781018 0.02494362]\n",
      "std alpha [0.15590775 0.15399206] std K [0.36769337 0.09130023]\n"
     ]
    }
   ],
   "source": [
    "mean_a2 = np.load(\"mean_a2.npy\")\n",
    "mean_k2 = np.load(\"mean_k2.npy\")\n",
    "std_a2 = np.load(\"std_a2.npy\")\n",
    "std_k2 = np.load(\"std_k2.npy\")\n",
    "print(\"mean alpha\",mean_a2,\"mean K\",mean_k2)\n",
    "print(\"std alpha\",std_a2,\"std K\",std_k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6129efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean alpha [1.0067722 0.01     ] mean K [1.07781018e+00 1.00000000e-04]\n",
      "std alpha [0.15590775 0.001     ] std K [3.67693371e-01 1.00000000e-05]\n"
     ]
    }
   ],
   "source": [
    "mean_a2 = np.array([mean_a2[0],0.01])\n",
    "mean_k2 = np.array([mean_k2[0],0.0001])\n",
    "std_a2 = np.array([std_a2[0],0.001])\n",
    "std_k2 = np.array([std_k2[0],0.00001])\n",
    "print(\"mean alpha\",mean_a2,\"mean K\",mean_k2)\n",
    "print(\"std alpha\",std_a2,\"std K\",std_k2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67790061",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"mean_a2.npy\",mean_a2)\n",
    "np.save(\"mean_k2.npy\",mean_k2)\n",
    "np.save(\"std_a2.npy\",std_a2)\n",
    "np.save(\"std_k2.npy\",std_k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c256590-4f2d-4f9d-b138-61c803adefd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting the oututp in the correct form from saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kvar, Kmean, avar, amean, times = [], [], [], [], []\n",
    "for e in range(N_EXP):\n",
    "    Kvar.append(np.load(f'std_k{e}.npy')**2)\n",
    "    avar.append(np.load(f'std_a{e}.npy')**2)\n",
    "    Kmean.append(np.load(f'mean_k{e}.npy'))\n",
    "    amean.append(np.load(f'mean_a{e}.npy'))\n",
    "    times.append(np.load(f'time{e}.npy'))\n",
    "\n",
    "EnsembleDat = []\n",
    "for e in range(N_EXP):\n",
    "    expDat = np.ones((5, 2))\n",
    "    expDat = [[],[],[],[],[]]\n",
    "    expDat[0] = Kmean[e]\n",
    "    expDat[1] = Kvar[e]\n",
    "    expDat[2] = amean[e]\n",
    "    expDat[3] = avar[e]\n",
    "    expDat[4] = times[e]\n",
    "    EnsembleDat.append(expDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the ensemble labels files in the same directories as the single-traj labels\n",
    "\n",
    "for e in range(N_EXP):\n",
    "    path_exp = path_track+f\"exp_{e}/\"\n",
    "    file_name = path_exp + 'ensemble_labels.txt'\n",
    "    with open(file_name, 'a') as f:\n",
    "        f.write(f'model: multi_state; num_state: {2} \\n')\n",
    "        np.savetxt(f, EnsembleDat[e], delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9fc6cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to draw boundaries by hand, not used here\n",
    "h0 = np.zeros(len(af))\n",
    "h1 = np.ones(len(af))\n",
    "hand_labels = np.where(((af <0.5) & (kf<0.3)), h0,h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()# Plot the results\n",
    "plt.scatter(coordinates[:, 0], coordinates[:, 1], c=hand_labels, cmap='viridis', marker='o', s =0.2)\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='x')\n",
    "plt.xlabel('$\\\\alpha$')\n",
    "plt.ylabel('K')\n",
    "plt.xlim(0,2)\n",
    "#     plt.ylim(0,4)\n",
    "plt.title('K-Means Clustering for sub 2  exp'+str(exp))\n",
    "plt.show()\n",
    "#     fig.savefig('exp_'+str(exp)+'_T_T.pdf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
