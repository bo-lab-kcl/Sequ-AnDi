{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to TF environment\n",
    "from tensorflow.keras.models import  Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Masking, TimeDistributed, Input\n",
    "from tensorflow.keras import backend as K\n",
    "import scipy.io as sci\n",
    "import h5py\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import math\n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential info about the input and output filepaths\n",
    "\n",
    "N_EXP = 12 # number of experiments\n",
    "N_FOVS = 30 # number of fields of view per experiment\n",
    "\n",
    "# We only to track 2 in this example\n",
    "track = 2\n",
    "\n",
    "# Raw trajectory Dataset Filepath (input)\n",
    "path_trajectoryDat = \"ref/\"\n",
    "\n",
    "# Results filepath for saving\n",
    "path_results = ''\n",
    "path_track = path_results + f'track_{track}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 2 # spatial dimension \n",
    "minSeg = 3 # minimum segment length allowed\n",
    "padval = -99. # padding value that is masked by the nets\n",
    "maxLen = 200 # maximum trajectory length allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to define the loss functions for the models below\n",
    "def masked_mse(y_true, y_pred, padval=-99.):\n",
    "    a_output = y_pred[:, :, 0]\n",
    "    K_output = y_pred[:, :, 1]\n",
    "    true_a = y_true[:, :, 0]\n",
    "    true_K = y_true[:, :, 1]\n",
    "\n",
    "    # MSE for alpha\n",
    "    mask = K.cast(K.not_equal(true_a, padval), dtype=a_output.dtype)\n",
    "    squared_diff = K.square(true_a - a_output)\n",
    "    masked_squared_diff = squared_diff * mask\n",
    "\n",
    "    #MSLE for K\n",
    "    true_K=true_K*mask\n",
    "    K_output=K_output*mask\n",
    "    log_diff = K.square(K.log(true_K+1) - K.log(K_output+1))\n",
    "    masked_log_diff = log_diff * mask\n",
    "\n",
    "    # Summing and averaging over the non-padded timesteps\n",
    "    num_non_padding = K.sum(mask)\n",
    "    mse = K.sum(masked_squared_diff) / (num_non_padding + K.epsilon())  + 2*K.sum(masked_log_diff) / (num_non_padding + K.epsilon())\n",
    "    return mse\n",
    "\n",
    "def masked_mae(y_true, y_pred): # masked mean absolute error\n",
    "    padval=-99.\n",
    "    float_output = y_pred\n",
    "    true_float = y_true\n",
    "\n",
    "    mask = K.cast(K.not_equal(true_float, padval), dtype=float_output.dtype)\n",
    "    squared_diff = K.cast(K.abs(true_float - float_output), dtype=float_output.dtype)\n",
    "    masked_squared_diff = squared_diff * mask\n",
    "    # Summing and averaging over the non-padded timesteps\n",
    "    num_non_padding = K.sum(mask)\n",
    "    mse = K.sum(masked_squared_diff) / (num_non_padding + K.epsilon())  # Adding epsilon to avoid division by zero\n",
    "    return mse\n",
    "\n",
    "def OrdEnt(y_true, y_pred): # an *ordinal* sparse categorical crossentropy\n",
    "    maxInt = 3.\n",
    "    padval=int(-99.)\n",
    "    numCP_true = tf.cast(y_true, dtype=tf.int32)\n",
    "    numCP_pred = y_pred\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(numCP_true, padval), dtype=numCP_true.dtype)\n",
    "    numCP_true=numCP_true*mask # cant have -99 in the label for cross ent\n",
    "\n",
    "    numCP_loss = K.sparse_categorical_crossentropy(numCP_true, numCP_pred)\n",
    "    mask=tf.cast(mask, dtype=numCP_loss.dtype)\n",
    "    numCP_loss = numCP_loss * mask\n",
    "    weights = K.abs(K.cast(numCP_true, dtype=tf.float32) - K.cast(K.argmax(numCP_pred, axis=-1),dtype=tf.float32))/maxInt\n",
    "\n",
    "    return tf.reduce_sum((1.0+weights*mask)*numCP_loss) / tf.cast(tf.reduce_sum(mask), dtype=numCP_loss.dtype)\n",
    "\n",
    "def maskedBin(y_true, y_pred): # masked binary entropy\n",
    "    padval=int(-99.)\n",
    "    numCP_true = tf.cast(y_true, dtype=tf.int32)\n",
    "    numCP_pred = y_pred\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(numCP_true, padval), dtype=numCP_true.dtype)\n",
    "    numCP_true=numCP_true*mask # cant have -99 in the label for cross ent\n",
    "\n",
    "    numCP_loss = K.binary_crossentropy(tf.cast(numCP_true, dtype=numCP_pred.dtype), numCP_pred)\n",
    "    numCP_loss = numCP_loss*tf.cast(mask, dtype=numCP_loss.dtype)\n",
    "\n",
    "    return tf.reduce_sum(numCP_loss) / tf.cast(tf.reduce_sum(mask), dtype=numCP_loss.dtype)\n",
    "\n",
    "def masked_categorical_crossentropy(y_true, y_pred): # masked categorical cross entropy for multiclass OHE label\n",
    "    one_hot_output = y_pred[:, :, :4]\n",
    "    true_one_hot = y_true[:, :, :4]\n",
    "    padval=-99.\n",
    "    mask = tf.reduce_any(tf.not_equal(true_one_hot, padval), axis=-1)\n",
    "    mask = tf.cast(mask, true_one_hot.dtype)\n",
    "    \n",
    "    loss = tf.keras.losses.categorical_crossentropy(true_one_hot, one_hot_output, from_logits=False)\n",
    "    loss = loss * mask # float 32vs64\n",
    "    \n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n",
    "def int_acc(y_true, y_pred): # masked accuracy from sparse (integer) labels\n",
    "    padval=int(-99.)\n",
    "    numCP_true = tf.cast(y_true, tf.int64)\n",
    "    numCP_pred = y_pred\n",
    "\n",
    "    mask = tf.not_equal(numCP_true, padval)\n",
    "    correct_predictions = tf.equal(numCP_true, tf.argmax(numCP_pred, axis=-1))\n",
    "    acc = tf.reduce_sum(tf.cast(correct_predictions, tf.float32) * tf.cast(mask, tf.float32)) / tf.reduce_sum(tf.cast(mask, tf.float32))\n",
    "    return acc\n",
    "\n",
    "def one_hot_accuracy(y_true, y_pred): # masked accuracy from one hot encoded labels\n",
    "    padval=-99.\n",
    "    true_labels = y_true[:, :, :4] # 4 class - one hot encoding\n",
    "    pred_labels = y_pred[:, :, :4]\n",
    "    mask = tf.reduce_all(tf.not_equal(true_labels, padval), axis=-1)\n",
    "    correct_predictions = tf.equal(tf.argmax(true_labels, axis=-1), tf.argmax(pred_labels, axis=-1))\n",
    "    accuracy = tf.reduce_sum(tf.cast(correct_predictions, tf.float32) * tf.cast(mask, tf.float32)) / tf.reduce_sum(tf.cast(mask, tf.float32))\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None, 9)]    0           []                               \n",
      "                                                                                                  \n",
      " masking_1 (Masking)            (None, None, 9)      0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, None, 250)    260000      ['masking_1[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, None, 50)     60200       ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " yn_output (TimeDistributed)    (None, None, 1)      51          ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " OH_output (TimeDistributed)    (None, None, 4)      204         ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 320,455\n",
      "Trainable params: 320,455\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def buildArchitectureCPtOnly(minSeg, padval, dimension): # defines network for model to predict where changepoints occur\n",
    "    block_size = minSeg*(dimension+1)                                   # Size of the blocks of data points\n",
    "\n",
    "    input_shape = (None, block_size)  \n",
    "    inputs = Input(shape=input_shape)\n",
    "    masked_inputs = Masking(mask_value=padval)(inputs) # masking layer with specific padding value\n",
    "\n",
    "    lstm_out = LSTM(250,                              # first layer: LSTM of dimension 250\n",
    "                    return_sequences=True,            # return sequences for the second LSTM layer            \n",
    "                    recurrent_dropout=0.2,            # recurrent dropout for preventing overtraining\n",
    "                    input_shape=(None, block_size))(masked_inputs)\n",
    "    # but LSTM input is 3D, this is added on as batch size later? should batches have same length trajectories or just blocks constant\n",
    "                                                            \n",
    "    lstm2_out = LSTM(50,                              # second layer: LSTM of dimension 50\n",
    "                    return_sequences=True,            # also returns sequences, into the TimeDistributed\n",
    "                    recurrent_dropout=0.2,           \n",
    "                    dropout=0)(lstm_out)\n",
    "    \n",
    "    yn_output_layer = TimeDistributed(Dense(1, activation='sigmoid'), name='yn_output')(lstm2_out) # 1 binary prediction per sequence point\n",
    "    OH_output_layer = TimeDistributed(Dense(4, activation='softmax'), name='OH_output')(lstm2_out) # ordinal classification for exact changepoint location in block\n",
    "    model_inference = Model(inputs=inputs, outputs=[yn_output_layer,OH_output_layer])\n",
    "    model_inference.compile(optimizer='adam', \n",
    "                            loss={\n",
    "                                  'yn_output':maskedBin,\n",
    "                                  'OH_output':OrdEnt}, \n",
    "                            metrics={\n",
    "                                     'yn_output':'accuracy',\n",
    "                                     'OH_output':int_acc}, \n",
    "                            loss_weights={\n",
    "                                  'yn_output':1.,\n",
    "                                  'OH_output':1.})\n",
    "    \n",
    "    print(model_inference.summary())\n",
    "\n",
    "    return model_inference\n",
    "\n",
    "model_CPtOnly = buildArchitectureCPtOnly(minSeg, padval, dimension)\n",
    "\n",
    "model_CPtOnly.load_weights('DynamicCP_Weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, None, 9)]    0           []                               \n",
      "                                                                                                  \n",
      " masking_2 (Masking)            (None, None, 9)      0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, None, 250)    260000      ['masking_2[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, None, 50)     60200       ['lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      " fl_output (TimeDistributed)    (None, None, 2)      102         ['lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      " yn_output (TimeDistributed)    (None, None, 1)      51          ['lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      " OH_output (TimeDistributed)    (None, None, 4)      204         ['lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 320,557\n",
      "Trainable params: 320,557\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def buildArchitectureCPtKandA(minSeg, padval, dimension): # defines the network for the model predicting changepoints, K and alpha\n",
    "    \n",
    "    block_size = minSeg*(dimension+1)                               \n",
    "\n",
    "    input_shape = (None, block_size)  \n",
    "    inputs = Input(shape=input_shape)\n",
    "    masked_inputs = Masking(mask_value=padval)(inputs)\n",
    "\n",
    "    lstm_out = LSTM(250,                            \n",
    "                    return_sequences=True,                      \n",
    "                    recurrent_dropout=0.2,            \n",
    "                    input_shape=(None, block_size))(masked_inputs)\n",
    "                                                            \n",
    "    lstm2_out = LSTM(50,                              \n",
    "                    return_sequences=True,          \n",
    "                    recurrent_dropout=0.2,           \n",
    "                    dropout=0)(lstm_out)\n",
    "    \n",
    "    fl_output_layer = TimeDistributed(Dense(2), name='fl_output')(lstm2_out) # 2 floats: alpha and K, for regression on every point in sequence\n",
    "    yn_output_layer = TimeDistributed(Dense(1, activation='sigmoid'), name='yn_output')(lstm2_out)\n",
    "    OH_output_layer = TimeDistributed(Dense(4, activation='softmax'), name='OH_output')(lstm2_out)\n",
    "    model_inference = Model(inputs=inputs, outputs=[fl_output_layer,yn_output_layer,OH_output_layer])\n",
    "    model_inference.compile(optimizer='adam', \n",
    "                            loss={'fl_output':masked_mse,\n",
    "                                  'yn_output':maskedBin,\n",
    "                                  'OH_output':OrdEnt}, \n",
    "                            metrics={'fl_output':masked_mae,\n",
    "                                     'fl_output':masked_mse,\n",
    "                                     'yn_output':'accuracy',\n",
    "                                     'OH_output':int_acc}, \n",
    "                            loss_weights={'fl_output':1.,\n",
    "                                  'yn_output':1.,\n",
    "                                  'OH_output':1.})\n",
    "    \n",
    "    print(model_inference.summary())\n",
    "\n",
    "    return model_inference\n",
    "\n",
    "model_CPtKanda = buildArchitectureCPtKandA(minSeg, padval, dimension)\n",
    "\n",
    "model_CPtKanda.load_weights('DynamicCP_KandA_Weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, None, 9)]    0           []                               \n",
      "                                                                                                  \n",
      " masking_3 (Masking)            (None, None, 9)      0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  (None, None, 250)    260000      ['masking_3[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)                  (None, None, 50)     60200       ['lstm_6[0][0]']                 \n",
      "                                                                                                  \n",
      " float_output (TimeDistributed)  (None, None, 2)     102         ['lstm_7[0][0]']                 \n",
      "                                                                                                  \n",
      " one_hot_output (TimeDistribute  (None, None, 4)     204         ['lstm_7[0][0]']                 \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 320,506\n",
      "Trainable params: 320,506\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def buildArchitectureModelKandA(minSeg, padval, dimension): # model predicts the time-varying diffustion type, K and alpha\n",
    "\n",
    "    block_size = minSeg*(dimension+1)\n",
    "\n",
    "    input_shape = (None, block_size)  \n",
    "    inputs = Input(shape=input_shape)\n",
    "    masked_inputs = Masking(mask_value=padval)(inputs)\n",
    "\n",
    "    lstm_out = LSTM(250,                            \n",
    "                    return_sequences=True,                      \n",
    "                    recurrent_dropout=0.2,            \n",
    "                    input_shape=(None, block_size))(masked_inputs)\n",
    "                                                            \n",
    "    lstm2_out = LSTM(50,                              \n",
    "                    return_sequences=True,          \n",
    "                    recurrent_dropout=0.2,           \n",
    "                    dropout=0)(lstm_out)\n",
    "    \n",
    "    float_output_layer = TimeDistributed(Dense(2), name='float_output')(lstm2_out) # 2 floats, K and alpha\n",
    "    one_hot_output_layer = TimeDistributed(Dense(4, activation='softmax'), name='one_hot_output')(lstm2_out) # 4 different diffusion classes/models\n",
    "\n",
    "    model_inference = Model(inputs=inputs, outputs=[float_output_layer, one_hot_output_layer])\n",
    "    model_inference.compile(optimizer='adam', \n",
    "                            loss={'float_output':masked_mse,\n",
    "                                  'one_hot_output':masked_categorical_crossentropy}, \n",
    "                            metrics={'float_output':masked_mae,\n",
    "                                     'one_hot_output':one_hot_accuracy},\n",
    "                            loss_weights={\n",
    "                                  'float_output':1.,\n",
    "                                  'one_hot_output':2.})\n",
    "    print(model_inference.summary())\n",
    "\n",
    "    return model_inference\n",
    "\n",
    "model_Modelt = buildArchitectureModelKandA(minSeg, padval, dimension)\n",
    "\n",
    "model_Modelt.load_weights('DynamicDiffType_KandA_Weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation; retrieves *increments* from the positions, normalises them, and pads the trajectories to accomodate the blocks.\n",
    "def data_prepare(X,N,dimension,blocksize,padval,maxLen):                 \n",
    "    thr=1e-10\n",
    "    r = [np.diff(xi,axis=1) for xi in X] # taking the increments along each dimension of each trajectory\n",
    "    sxy = [np.std(ri.flatten()) for ri in r] # the std of both x and y increments of each trajectory\n",
    "    meanxy = [np.mean(ri.flatten()) for ri in r] # the mean of both x and y increments of each trajectory\n",
    "\n",
    "    # maxLen=(maxLen-1)//minSeg + 1\n",
    "    maxLen = (maxLen-1)//minSeg + (1 if (maxLen-1)%minSeg != 0 else 0)\n",
    "    datLen = int(blocksize/minSeg) # size of the vector for each position.\n",
    "    \n",
    "    x = []\n",
    "    for i, ri in enumerate(r): # each iteration a different traj\n",
    "        trajlen=len(ri[0])\n",
    "        y=ri\n",
    "        mu=np.full((dimension,1),meanxy[i])\n",
    "        sig=np.full((dimension,1),sxy[i])\n",
    "        y = (y-mu) / np.where(sxy[i]>thr,sig,1)   # len(y) == dimension\n",
    "        y = np.array([[y[0][n], y[1][n],sxy[i]] for n in range(trajlen)]) # stack on the std of xy\n",
    "        y=np.transpose(y,axes=[1,0])\n",
    "        if (trajlen%minSeg) != 0:\n",
    "            y = np.concatenate((y,np.full((datLen,minSeg-(trajlen%minSeg)),padval)),axis=1) \n",
    "\n",
    "        padding = maxLen-int(datLen*len(y[0])/blocksize) # This padding does not affect the predictions, but having all trajectories be the same length helps to process together in arrays.\n",
    "        if  padding > 0:\n",
    "            y = np.concatenate((y,np.full((datLen,padding*minSeg),padval)),axis=1)\n",
    "\n",
    "        y=np.transpose(y,axes=[1,0])\n",
    "        y=y.reshape(int(datLen*(len(y))/blocksize),blocksize)\n",
    "        x.append(np.array(y))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'track_2/exp_0/trajs_fov_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EXP):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fov \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_FOVS):\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path_trajectoryDat\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_2/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(exp)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/trajs_fov_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(fov)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csv_file: \u001b[38;5;66;03m# just change this path to the dataset you want predictions for.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m             csv_reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(csv_file)\n\u001b[1;32m      7\u001b[0m             line_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'track_2/exp_0/trajs_fov_0.csv'"
     ]
    }
   ],
   "source": [
    "X = [[] for _ in range(N_EXP)]\n",
    "trfoIdx = [[] for _ in range(N_EXP)]\n",
    "for exp in range(N_EXP):\n",
    "    for fov in range(N_FOVS):\n",
    "        with open(path_trajectoryDat+'track_2/'+\"exp_\"+str(exp)+\"/trajs_fov_\"+str(fov)+'.csv','r') as csv_file: # just change this path to the dataset you want predictions for.\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            line_count = 0\n",
    "            traj = []\n",
    "            t = 0\n",
    "            for row in csv_reader:\n",
    "                if line_count == 0:\n",
    "                    # print(f'Column names are {\", \".join(row)}')\n",
    "                    line_count += 1\n",
    "                else:\n",
    "                    if float(row[0]) == t:\n",
    "                        traj.append([float(row[2]),float(row[3])]) # just keep X and Y\n",
    "                    else: \n",
    "                        X[exp].append(traj)\n",
    "                        t += 1\n",
    "                        traj = []\n",
    "                        traj.append([float(row[2]),float(row[3])])\n",
    "            t += 1\n",
    "            trfoIdx[exp].append(t)\n",
    "            X[exp].append(traj) # last trajectory in the fov\n",
    "X = np.array(X)\n",
    "trajlens=[len(X[i][j]) for i in range(N_EXP) for j in range(len(X[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedX = [[] for _ in range(N_EXP)]\n",
    "for exp in range(N_EXP):\n",
    "    for i in range(len(X[exp])):\n",
    "        sortedX[exp].append(list(np.array(X[exp][i])[:,0])+list(np.array(X[exp][i])[:,1]))\n",
    "dimsortX=[[np.array(i).reshape(dimension,-1) for i in x] for x in sortedX]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = minSeg*(dimension+1)\n",
    "Xin = [data_prepare(dimsortX[i],len(dimsortX[i]),dimension,block_size,padval, maxLen) for i in range(N_EXP)] # Prepare the data for the nets\n",
    "Xin2 = [data_prepare([x[:,1:] for x in dimsortX[i]],len(dimsortX[i]),dimension,block_size,padval, maxLen) for i in range(N_EXP)] # Prepare it again, shifting (with a cut) by 1 point\n",
    "Xin3 = [data_prepare([x[:,2:] for x in dimsortX[i]],len(dimsortX[i]),dimension,block_size,padval, maxLen) for i in range(N_EXP)] # shift by 2 points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modtPred = [model_Modelt.predict(np.array(x)) for x in Xin]\n",
    "# modtPred2 = [model_Modelt.predict(np.array(x)) for x in Xin2]\n",
    "# modtPred3 = [model_Modelt.predict(np.array(x)) for x in Xin3]\n",
    "ModT = [np.argmax(e[1],axis=-1) for e in modtPred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predCPtKanda = [model_CPtKanda.predict(np.array(x)) for x in Xin]\n",
    "predCPtKanda2 = [model_CPtKanda.predict(np.array(x)) for x in Xin2]\n",
    "predCPtKanda3 = [model_CPtKanda.predict(np.array(x)) for x in Xin3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptPred = [model_CPtOnly.predict(np.array(x)) for x in Xin]\n",
    "cptPred2 = [model_CPtOnly.predict(np.array(x)) for x in Xin2]\n",
    "cptPred3 = [model_CPtOnly.predict(np.array(x)) for x in Xin3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundThresh(arr, thr=0.5): # you may change the threhsold for rounding the binary prediction if you wish\n",
    "    newarr=[]\n",
    "    for d in arr:\n",
    "        if d >= thr:\n",
    "            d = -(d // -1)\n",
    "        newarr.append(d // 1)\n",
    "    return np.array(newarr).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Sliding Window\n",
    "alphaMeansPred = [[] for _ in range(N_EXP)]\n",
    "KMeansPred = [[] for _ in range(N_EXP)]\n",
    "CPWinPred = [[] for _ in range(N_EXP)] # changepoint storage\n",
    "for e in range(N_EXP):\n",
    "    for t, traj in enumerate(dimsortX[e]):\n",
    "        incLen = len(traj[0])-1 # number of increments \n",
    "        coarseLen=incLen//minSeg + (1 if incLen%minSeg != 0 else 0) # length of \"coarse-grained\" increment sequence input to the nets\n",
    "\n",
    "        # extract the length of useful (unpadded) sequence in the in/output of the nets, for original (Xin) and shifted (Xin2, Xin3) trajectories\n",
    "        check = len([p for p in Xin[e][t][:,0] if p != padval]) \n",
    "        check2 = len([p for p in Xin2[e][t][:,0] if p != padval]) \n",
    "        check3 = len([p for p in Xin3[e][t][:,0] if p != padval])\n",
    "        if check != coarseLen:\n",
    "            print('AH')\n",
    "\n",
    "        alphaWindowsPred = [[] for _ in range(incLen)] # tracking the value of alpha over the fully discretised time\n",
    "        KWindowsPred = [[] for _ in range(incLen)] # tracking the value of K over the fully discretised time\n",
    "        cpsTrajPred = np.zeros(incLen) # for tracking changepoint detections over the discretised time\n",
    "\n",
    "        predBinwin = roundThresh(cptPred[e][0][t][:,0])[:coarseLen] # extract binary CP detections from unshifted\n",
    "        predBinwin2 = roundThresh(cptPred2[e][0][t][:,0])[:check2] # extract binary CP detections from trajectory shifted by 1\n",
    "        predBinwin3 = roundThresh(cptPred3[e][0][t][:,0])[:check3] # extract binary CP detections from trajectory shifted by 2\n",
    "        predIntwin = np.argmax(cptPred[e][1][t], axis=-1)[:coarseLen] # extract precise block-CP detections\n",
    "        predIntwin2 = np.argmax(cptPred2[e][1][t], axis=-1)[:check2] \n",
    "        predIntwin3 = np.argmax(cptPred3[e][1][t], axis=-1)[:check3]\n",
    "\n",
    "        for i in range(incLen):\n",
    "            alphaWindowsPred[i].append(predCPtKanda[e][0][t][:, 0][i//minSeg]) # taking coarse grained alpha predictions to the complete-time array\n",
    "            KWindowsPred[i].append(predCPtKanda[e][0][t][:, 1][i//minSeg]) # K\n",
    "            cpsTrajPred[i] += predBinwin[i//minSeg] # record the binary classification predictions\n",
    "        for i in range(incLen-1): # for the shifted trajectory\n",
    "            alphaWindowsPred[i+1].append(predCPtKanda2[e][0][t][:, 0][i//minSeg])\n",
    "            KWindowsPred[i+1].append(predCPtKanda2[e][0][t][:, 1][i//minSeg])\n",
    "            cpsTrajPred[i+1] += predBinwin2[i//minSeg]\n",
    "        for i in range(incLen-2): # for the twice shifted trajectory\n",
    "            alphaWindowsPred[i+2].append(predCPtKanda3[e][0][t][:, 0][i//minSeg])\n",
    "            KWindowsPred[i+2].append(predCPtKanda3[e][0][t][:, 1][i//minSeg])\n",
    "            cpsTrajPred[i+2] += predBinwin3[i//minSeg] \n",
    "\n",
    "        for idx, cp in enumerate(predIntwin): # recording the ordinal classification predictions \n",
    "            if cp != 0:\n",
    "                cpsTrajPred[idx*minSeg + cp - 1] += 1 # add one back in (shift right) for real CP, not the increment version this is (-1)\n",
    "        for idx, cp in enumerate(predIntwin2):\n",
    "            if cp != 0:\n",
    "                cpsTrajPred[1+idx*minSeg + cp - 1] += 1\n",
    "        for idx, cp in enumerate(predIntwin3):\n",
    "            if cp != 0:\n",
    "                cpsTrajPred[2+idx*minSeg + cp - 1] += 1\n",
    "\n",
    "        alphaMeansPred[e].append([np.mean(a) for a in alphaWindowsPred])\n",
    "        KMeansPred[e].append([np.mean(a) for a in KWindowsPred])\n",
    "        CPWinPred[e].append(find_peaks(cpsTrajPred,height=2,distance=minSeg)[0] + 1) # noting the prominent detections from cpsTrajPred \"histogram\", note +1 put back\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCPsWin = [np.array([len(CPWinPred[e][t]) for t in range(len(CPWinPred[e]))]) for e in range(N_EXP)] # number of changepoints detected per trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for e in range(N_EXP):\n",
    "    # directory = 'public_data_challenge_v0/res/track_2/exp_'+str(e)\n",
    "    directory = path_track + 'exp_'+str(e)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our predictions\n",
    "\n",
    "h, h1, h2, h3=0, 0, 0, 0\n",
    "for e in range(N_EXP):    \n",
    "    path_exp = path_track + f'exp_{e}/'\n",
    "    t = 0\n",
    "    for fov in range(N_FOVS):\n",
    "        submission_file = path_exp + f'fov_{fov}.txt'\n",
    "        with open(submission_file, 'w') as f:\n",
    "            for idx in range(trfoIdx[e][fov]):\n",
    "                prediction_traj = []\n",
    "                length = len(X[e][t])\n",
    "                if len(CPWinPred[e][t]) == 0: # if no changepoint detected in the trajectory\n",
    "                    Ks = np.mean(KMeansPred[e][t]) # take average K(t) value of entire trajectory\n",
    "                    if Ks < 0:\n",
    "                        Ks = 0.0001\n",
    "                    As = np.mean(alphaMeansPred[e][t])\n",
    "                    if As < 0:\n",
    "                        As = 0.\n",
    "                    if e==2 and As < 0.38: # only for experiment 02\n",
    "                        As = 0.\n",
    "                        Ks= 0.0001\n",
    "                    Mods = int(stats.mode(ModT[e][t][:int(-(length // -3))]).mode) # diffustion type just given by the mode\n",
    "                    # print(diffType)\n",
    "                    prediction_traj = [idx,\n",
    "                                       Ks, \n",
    "                                       As, \n",
    "                                       Mods,\n",
    "                                       length]\n",
    "\n",
    "                elif len(CPWinPred[e][t]) >0: # if changepoints present\n",
    "                    prediction_traj = [idx]\n",
    "                    cp2= 1\n",
    "                    # print(e, t)\n",
    "                    for t_id, time in enumerate(list(CPWinPred[e][t])+[length]): # must have traj.length at the end to calculate last segment\n",
    "                        h+=1\n",
    "                        cp = time\n",
    "                        if cp > length: \n",
    "                            h2+=1\n",
    "                            continue\n",
    "                        if cp2 > cp:\n",
    "                            h3+=1\n",
    "                            continue\n",
    "\n",
    "                        Ks = np.mean(KMeansPred[e][t][(cp2-1):(cp-1)]) # bc list is of real CPs not increments which need -1\n",
    "                        if Ks < 0:\n",
    "                            Ks = 0.0001\n",
    "\n",
    "                        As = np.mean(alphaMeansPred[e][t][(cp2-1):(cp-1)])\n",
    "                        if As < 0:\n",
    "                            As = 0.\n",
    "                        if e==2 and As < 0.38: # specific to experiment 02 trapped datapoints.\n",
    "                            As = 0.\n",
    "                            Ks= 0.0001\n",
    "                        if math.isnan(As):\n",
    "                            print(e, t, cp)\n",
    "                        prediction_traj.append(Ks)\n",
    "                        prediction_traj.append(As)\n",
    "\n",
    "                        Mods = ModT[e][t][(cp2-1)//3:(cp-1)//3]\n",
    "                        if len(Mods) == 0:\n",
    "                            Mods = ModT[e][t][(cp-1)//3]\n",
    "                        else:\n",
    "                            Mods = stats.mode(Mods).mode\n",
    "                            Mods = int(Mods)\n",
    "\n",
    "                        prediction_traj.append(Mods)\n",
    "\n",
    "                        prediction_traj.append(cp)\n",
    "\n",
    "                        cp2 = np.copy(cp) # keep track of latest changepoint, for the next segment iteration.\n",
    "\n",
    "                else:\n",
    "                    print('no')\n",
    "                t += 1\n",
    "                formatted_numbers = ','.join(map(str, prediction_traj))\n",
    "                f.write(formatted_numbers + '\\n')\n",
    "          \n",
    "print(h,h2,h3)    \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
